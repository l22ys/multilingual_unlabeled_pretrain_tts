trainer: trainer_.trainer_P.Trainer
debug: True
trainer_data_path: null
np_seed: 10
wandb_enable: False
gpu: 1
fp16:
  use_amp: false
max_grad_norm: 1.0
total_epochs: 
total_steps: 
gradient_accumulation_steps: 1
loss_type: mean
gradient_checkpointing: false
find_unused_parameters: false
logging:
  log_dir: 
  seed: 
  save_freq: 1
  wandb_freq: 100
  save_freq_step : 1000
  error_log: error_log.txt
  latest_checkpoint_num: 2
for_wandb:
  project: 
  name: 
  config:
    batch_size: 3
    lr: 0.0001
    gradient_accumulation_steps: 1
datasets:
  train:
    conf_dataset:
      class: datasets_.mls.MLSLanguageBatchTrain
      pad_id: 0
      data_paths: # 'list' of txt files - named 'data_info_added.txt'
      fft_size: 1024
      hop_length: 256
      win_length: 1024
      sample_rate: 16000
      mel_fmin: 0
      mel_fmax: null
      num_mels: 80
      crop_size: 23778
    conf_dataloader:
      seed: 42
      batch_size: 3
      gradient_accumulation_steps: 1
      world_size: 1
      is_group_by_length: False
      num_workers: 4
      pin_memory: false
      drop_last: True
      conf_collate_fn:
        class: datasets_.mls_collate_fn.DataCollator2
  eval:
    conf_dataset:
      class: datasets_.mls.MLSLanguageBatchEval
      pad_id: 0
      data_paths: # 'list' of txt files - named 'data_info_added.txt'
      fft_size: 1024
      hop_length: 256
      win_length: 1024
      sample_rate: 16000
      mel_fmin: 0
      mel_fmax: null
      num_mels: 80
      crop_size: 23778
    conf_dataloader:
      seed: 42
      batch_size: 3
      gradient_accumulation_steps: 1
      world_size: 1
      is_group_by_length: False
      num_workers: 4
      pin_memory: false
      drop_last: True
      conf_collate_fn:
        class: datasets_.mls_collate_fn.DataCollator2
models:
  Gen:
    class: models_.vits_family.P3

    inference_noise_scale_dp : 1.0
    length_scale : 1
    inference_noise_scale : 0.667
    max_inference_len: null
    
    num_languages: 7
    embedded_language_dim: 4

    num_chars: 897 # 128 * num_languages + 1 = 897
    hidden_channels: 192
    pos_enc_hidden_channels: 192
    hidden_channels_ffn_text_encoder: 768
    num_heads_text_encoder: 2
    num_layers_text_encoder: 12
    kernel_size_text_encoder: 3
    dropout_p_text_encoder: 0.1
    heads_share: False

    out_channels: 513 
    kernel_size_posterior_encoder: 5
    dilation_rate_posterior_encoder: 1
    num_layers_posterior_encoder: 16
    
    embedded_speaker_dim: 192
    num_speakers: 169

    kernel_size_flow: 5
    dilation_rate_flow: 1
    num_layers_flow: 4

    spec_segment_size: 32

    encoder_sample_rate: null
    interpolate_factor: null
    interpolate_z: true
    
    resblock_type_decoder: '1'
    resblock_dilation_sizes_decoder: [[1,3,5],[1,3,5],[1,3,5]]
    resblock_kernel_sizes_decoder: [3,7,1]
    upsample_kernel_sizes_decoder: [16,16,4,4]
    upsample_initial_channel_decoder: 512
    upsample_rates_decoder: [8,8,2,2]

    audio:
      hop_length: 256
    use_speaker_encoder_as_loss: false
    speaker_manager:
      encoder: null

    optim:
      class: torch.optim.Adam
      weight_decay: 0
      kwargs:
        lr: 0.0001
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
      scheduler:
        use_scheduler: false

  Dis:
    class: models_.vits.discriminator.WrappedVitsDiscriminator
    periods_multi_period_discriminator: [2,3,5,7,11]
    use_spectral_norm_disriminator: false
    optim:
      class: torch.optim.Adam
      weight_decay: 0
      kwargs:
        lr: 0.0001
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
      scheduler:
        use_scheduler: false
    
losses:
  Gen:
    class: losses_.vits_losses.VitsGeneratorLosswithoutDur
    kl_loss_alpha: 1.0
    gen_loss_alpha: 1.0
    feat_loss_alpha: 1.0
    mel_loss_alpha: 45.0
    speaker_encoder_loss_alpha: 1.0
    audio:
      fft_size: 1024
      hop_length: 256
      win_length: 1024
      sample_rate: 16000
      mel_fmin: 0
      mel_fmax: null
      num_mels: 80
  Dis:
    class: losses_.vits_losses.VitsDiscriminatorLoss
    disc_loss_alpha: 1.0
